{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoRBLMQx94FA"
      },
      "source": [
        "%%capture\n",
        "!pip3 install datasets\n",
        "!pip3 install transformers\n",
        "!pip3 install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6I8RSxz-E_E"
      },
      "source": [
        "!wget https://huggingface.co/datasets/vasudevgupta/data/resolve/main/test.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8kivMbX0PQc"
      },
      "source": [
        "from transformers import pipeline, PegasusForConditionalGeneration, PegasusTokenizer, GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# for running GPT2-large:\n",
        "# revision = \"4c2361ee5aee22d127590fed42d2e0b7da3ffb0d\"\n",
        "# model_id = \"vasudevgupta/dl-hack-gpt2-large\"\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained(model_id, revision=revision)\n",
        "# model = GPT2LMHeadModel.from_pretrained(model_id, revision=revision).to(\"cuda\")\n",
        "\n",
        "# for using distil-gpt2:\n",
        "model_id = \"vasudevgupta/dl-hack-distilgpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_id)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_id).to(\"cuda\")\n",
        "\n",
        "# for using pegasus-large:\n",
        "# model_id = \"vasudevgupta/dl-hack-pegasus-large\"\n",
        "# tokenizer = PegasusTokenizer.from_pretrained(model_id)\n",
        "# model = PegasusForConditionalGeneration.from_pretrained(model_id).to(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hmULseODAcQ"
      },
      "source": [
        "input_ids = tokenizer(\"Incorporating BERT into parallel sequence decoding with adapters\", return_tensors=\"pt\")['input_ids']\n",
        "outputs = model.generate(input_ids.to(\"cuda\"), num_beams=8, max_length=512, no_repeat_ngram_size=2)\n",
        "tokenizer.decode(outputs[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdljSV3fGlP_"
      },
      "source": [
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "data = load_dataset(\"csv\", data_files=\"test.csv\")[\"train\"]\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmeHOHATHptS"
      },
      "source": [
        "abstracts = []\n",
        "titles = []\n",
        "for sample in tqdm(data, total=len(data)):\n",
        "  input_ids = tokenizer(sample['title'], return_tensors=\"pt\")['input_ids']\n",
        "  outputs = model.generate(input_ids.to(\"cuda\"), num_beams=8, max_length=512, no_repeat_ngram_size=2)\n",
        "  abstract = tokenizer.decode(outputs[0])\n",
        "  print(abstract)\n",
        "  abstracts.append(abstract)\n",
        "  titles.append(sample['title'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeTSuhrJixQy"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame.from_dict({\"title\": titles, \"abstract\": abstracts})\n",
        "df.to_csv(f\"predictions-{model_id}.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zva29ON_O7mV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}